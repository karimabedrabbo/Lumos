{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "from six.moves import cPickle\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, \\\n",
    "    Convolution2D, MaxPooling2D, ZeroPadding2D, Input, Embedding, LSTM, merge, \\\n",
    "    Lambda, UpSampling2D, Deconvolution2D, Cropping2D\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Activation, concatenate, Reshape, Permute\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from scipy.misc import toimage\n",
    "import itertools\n",
    "import h5py\n",
    "import skimage\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs, imgNorm):\n",
    "    for i in range(len(imgs)):\n",
    "        img = imgs[i]\n",
    "        if imgNorm == \"sub_and_divide\":\n",
    "            img = img.astype(np.float32)\n",
    "            img = img / 127.5 - 1\n",
    "        elif imgNorm == \"sub_mean\":\n",
    "            img = img.astype(np.float32)\n",
    "            img[:,:,0] -= 103.939\n",
    "            img[:,:,1] -= 116.779\n",
    "            img[:,:,2] -= 123.68\n",
    "        elif imgNorm == \"divide\":\n",
    "            img = img.astype(np.float32)\n",
    "            img = img/255.0\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    try:\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = cv2.resize(img, ( width , height ))\n",
    "        img = img[:, : , 0]\n",
    "\n",
    "        for c in range(nClasses):\n",
    "            seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    seg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
    "    return seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageSegmentationGenerator( images_path , segs_path ,  batch_size,  n_classes , input_height , input_width , output_height , output_width   ):\n",
    "    \n",
    "    assert images_path[-1] == '/'\n",
    "    assert segs_path[-1] == '/'\n",
    "\n",
    "    images = glob.glob( images_path + \"*.jpg\"  ) + glob.glob( images_path + \"*.png\"  ) +  glob.glob( images_path + \"*.jpeg\"  )\n",
    "    images.sort()\n",
    "    segmentations  = glob.glob( segs_path + \"*.jpg\"  ) + glob.glob( segs_path + \"*.png\"  ) +  glob.glob( segs_path + \"*.jpeg\"  )\n",
    "    segmentations.sort()\n",
    "\n",
    "    assert len( images ) == len(segmentations)\n",
    "    for im , seg in zip(images,segmentations):\n",
    "        assert(  im.split('/')[-1].split(\".\")[0] ==  seg.split('/')[-1].split(\".\")[0] )\n",
    "\n",
    "    zipped = itertools.cycle( zip(images,segmentations) )\n",
    "\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range( batch_size) :\n",
    "            im , seg = zipped.next()\n",
    "            X.append( getImageArr(im , input_width , input_height )  )\n",
    "            Y.append( getSegmentationArr( seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "        yield np.array(X) , np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cross_entropy(y_, y_conv):\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    y_true_f = K.clip(K.batch_flatten(y_true), 0., 1.)\n",
    "    y_pred_f = K.clip(K.batch_flatten(y_pred), 0., 1.)\n",
    "\n",
    "    intersection = 2 * K.sum(y_true_f * y_pred_f, axis=1)\n",
    "    union = K.sum(y_true_f * y_true_f, axis=1) + K.sum(y_pred_f * y_pred_f, axis=1)\n",
    "    return K.mean(intersection / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dice_loss(y_true, y_pred):\n",
    "    return -K.log(dice(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(y_true, y_pred):\n",
    "    \"\"\"An exact Dice score for binary tensors.\"\"\"\n",
    "    y_true_f = K.greater(y_true, 0.5)\n",
    "    y_pred_f = K.greater(y_pred, 0.5)\n",
    "    return dice(y_true_f, y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_other(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, 3), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        arr = imgs[i]\n",
    "        arr = arr.astype('float32')\n",
    "        arr /= 255.\n",
    "        imgs_p[i] = resize(arr, (img_cols, img_rows), preserve_range=True)\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_multi(arr, rows, cols, channels):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = skimage.transform.resize(arr[i], (rows, cols, channels))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(arr):\n",
    "    temp = []\n",
    "    for image in arr:\n",
    "        temp.append(image)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(numpy_arr, glauc_bool):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for image in numpy_arr:\n",
    "            X.append(image)\n",
    "            y.append(glauc_bool)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_image_numpy(imgs, rows, cols, channels):\n",
    "    total = len(imgs)\n",
    "    new = np.ndarray((total, rows, cols, channels), dtype=np.uint8)\n",
    "\n",
    "    for i in range(total):\n",
    "        new[i] = imgs[i]\n",
    "    \n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(path, im_type, backend):\n",
    "\n",
    "    images = glob.glob1(path,\"*.\" + str(im_type))\n",
    "    im_type_length = len(im_type) + 1\n",
    "    images = [element[:-im_type_length] for element in images]\n",
    "    images.sort(key=int)\n",
    "    images = [element + \".\" + str(im_type) for element in images]\n",
    "\n",
    "    if backend == \"keras\" or backend == \"Keras\" or backend == \"keras\":\n",
    "        images = [np.array(image.load_img(path + \"/\" + fname)) for fname in images]\n",
    "    if backend == \"opencv\" or backend == \"openCV\" or backend == \"OPENCV\" or backend == \"cv2\":\n",
    "        images = [np.array(cv2.imread(path + \"/\" + fname)) for fname in images]\n",
    "    if backend == \"PIL\" or backend == \"pil\":\n",
    "        images = [np.array(Image.open(path + \"/\" + fname)) for fname in images]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inter_model():\n",
    "#     model_vgg19_conv = VGG19(weights='imagenet', include_top=False, input_shape=(None,None,3))\n",
    "\n",
    "#     conv2_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv2_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-17].output)\n",
    "\n",
    "#     conv3_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv3_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-12].output)\n",
    "\n",
    "#     conv4_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv4_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-7].output)\n",
    "\n",
    "#     conv5_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv5_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-2].output)\n",
    "\n",
    "#     upsample2_ = Conv2DTranspose(filters=16, kernel_size=(4, 4), strides=(2, 2), padding = \"same\", name= \"upsample2_\", data_format=\"channels_last\")(conv2_3_16)\n",
    "    \n",
    "#     upsample4_ = Conv2DTranspose(filters=16, kernel_size=(8, 8), strides=(4, 4), padding = \"same\", name= \"upsample4_\", data_format=\"channels_last\")(conv3_3_16)\n",
    "\n",
    "#     upsample8_ = Conv2DTranspose(filters=16, kernel_size=(16, 16), strides=(8, 8), padding = \"same\",  name= \"upsample8_\", data_format=\"channels_last\")(conv4_3_16)\n",
    "\n",
    "#     upsample16_ = Conv2DTranspose(filters=16, kernel_size=(32, 32), strides=(16, 16), padding = \"same\", name= \"upsample16_\", data_format=\"channels_last\")(conv5_3_16)\n",
    "\n",
    "#     concat_upscore = concatenate([upsample2_, upsample4_, upsample8_, upsample16_], axis=-1)\n",
    "    \n",
    "#     \"\"\"\n",
    "#     new_score_weighting = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid', kernel_initializer=keras.initializers.Constant(value=0.01), name= \"new_score_weighting\", data_format=\"channels_last\")(concat_upscore)\n",
    "    \n",
    "#     my_model = Model(input=model_vgg19_conv.input , output=new_score_weighting)\n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "#     conv6 = Conv2D(filters=1, kernel_size=(1,1), activation='relu', kernel_initializer=keras.initializers.Constant(value=0.01), name= \"conv6\", data_format=\"channels_last\", border_mode='same')(concat_upscore)\n",
    "#     conv6 = Reshape((1,input_shape[0]*input_shape[1]))(conv6)\n",
    "#     conv6 = Permute((2,1))(conv6)\n",
    "\n",
    "#     conv7 = Activation('softmax')(conv6)\n",
    "\n",
    "#     my_model = Model(input=model_vgg19_conv.input, output=conv7)\n",
    "\n",
    "#     return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_model():\n",
    "    model_vgg19_conv = VGG19(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
    "\n",
    "    conv2_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv2_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-17].output)\n",
    "\n",
    "    conv3_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv3_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-12].output)\n",
    "\n",
    "    conv4_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv4_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-7].output)\n",
    "\n",
    "    conv5_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv5_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-2].output)\n",
    "\n",
    "    upsample2_ = Conv2DTranspose(filters=16, kernel_size=(4, 4), strides=(2, 2), padding = \"same\", name= \"upsample2_\", data_format=\"channels_last\")(conv2_3_16)\n",
    "    \n",
    "    upsample4_ = Conv2DTranspose(filters=16, kernel_size=(8, 8), strides=(4, 4), padding = \"same\", name= \"upsample4_\", data_format=\"channels_last\")(conv3_3_16)\n",
    "\n",
    "    upsample8_ = Conv2DTranspose(filters=16, kernel_size=(16, 16), strides=(8, 8), padding = \"same\",  name= \"upsample8_\", data_format=\"channels_last\")(conv4_3_16)\n",
    "\n",
    "    upsample16_ = Conv2DTranspose(filters=16, kernel_size=(32, 32), strides=(16, 16), padding = \"same\", name= \"upsample16_\", data_format=\"channels_last\")(conv5_3_16)\n",
    "\n",
    "    concat_upscore = concatenate([upsample2_, upsample4_, upsample8_, upsample16_], axis=-1)\n",
    "    \n",
    "    conv6 = Conv2D(filters=1, kernel_size=(1,1), activation='relu', kernel_initializer=keras.initializers.Constant(value=0.01), name= \"conv6\", data_format=\"channels_last\", border_mode='same')(concat_upscore)\n",
    "\n",
    "    \n",
    "    conv_1 = Conv2D(filters=32, kernel_size=(3, 3), name= \"conv_1\", activation = 'relu', data_format=\"channels_last\")(conv6)\n",
    "    max_pool1 = MaxPooling2D(pool_size=(2, 2), name= \"max_pool1\", data_format=\"channels_last\")(conv_1)\n",
    "    \n",
    "    conv_2 = Conv2D(filters=32, kernel_size=(3, 3), name= \"conv_2\", activation = 'relu', data_format=\"channels_last\")(max_pool1)\n",
    "    max_pool2 = MaxPooling2D(pool_size=(2, 2), name= \"max_pool2\", data_format=\"channels_last\")(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(filters=64, kernel_size=(3, 3), name= \"conv_3\", activation = 'relu', data_format=\"channels_last\")(max_pool2)\n",
    "    max_pool3= MaxPooling2D(pool_size=(2, 2), name= \"max_pool3\", data_format=\"channels_last\")(conv_3)\n",
    "\n",
    "    flatten = Flatten(input_shape = model_vgg19_conv.input.shape)(max_pool3)\n",
    "    dense_1 = Dense(16, activation='relu')(flatten)\n",
    "    dropout = Dropout(0.7)(dense_1)\n",
    "    dense_2 = Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "    my_model = Model(input=model_vgg19_conv.input, output=dense_2)\n",
    "    \n",
    "    my_model.summary()\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=<keras.ini..., name=\"conv6\", activation=\"relu\", data_format=\"channels_last\", padding=\"same\", filters=1, kernel_size=(1, 1))`\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 128, 128, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 128, 128, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 64, 64, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 64, 64, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 32, 32, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 32, 32, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 32, 32, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 32, 32, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 32, 32, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 16, 16, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 16, 16, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 8, 8, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 8, 8, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 8, 8, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 8, 8, 512)    2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_16 (Conv2D)             (None, 64, 64, 16)   18448       block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_16 (Conv2D)             (None, 32, 32, 16)   36880       block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_16 (Conv2D)             (None, 16, 16, 16)   73744       block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_16 (Conv2D)             (None, 8, 8, 16)     73744       block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsample2_ (Conv2DTranspose)    (None, 128, 128, 16) 4112        conv2_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "upsample4_ (Conv2DTranspose)    (None, 128, 128, 16) 16400       conv3_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "upsample8_ (Conv2DTranspose)    (None, 128, 128, 16) 65552       conv4_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "upsample16_ (Conv2DTranspose)   (None, 128, 128, 16) 262160      conv5_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 64) 0           upsample2_[0][0]                 \n",
      "                                                                 upsample4_[0][0]                 \n",
      "                                                                 upsample8_[0][0]                 \n",
      "                                                                 upsample16_[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 128, 128, 1)  65          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 126, 126, 32) 320         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)        (None, 63, 63, 32)   0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 61, 61, 32)   9248        max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)        (None, 30, 30, 32)   0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 28, 28, 64)   18496       max_pool2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pool3 (MaxPooling2D)        (None, 14, 14, 64)   0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           max_pool3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           200720      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,804,290\n",
      "Trainable params: 20,804,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model = get_classifier_model()\n",
    "classifier_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glauc = sort(\"/Users/karimabedrabbo/Desktop/work2/cropped_glauc_orig_png\", \"png\", \"keras\")\n",
    "not_glauc = sort(\"/Users/karimabedrabbo/Desktop/work2/cropped_not_glauc_orig_png\", \"png\", \"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_glauc = np.ones(len(glauc))\n",
    "y_not_glauc = np.zeros(len(not_glauc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "glauc = resize_multi(glauc, 128, 128, 3)\n",
    "not_glauc = resize_multi(not_glauc, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "glauc = multiple_image_numpy(glauc, 128, 128, 3)\n",
    "not_glauc = multiple_image_numpy(not_glauc, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "glauc = preprocess(glauc, \"divide\")\n",
    "not_glauc = preprocess(not_glauc, \"divide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = np.vstack((glauc, not_glauc))\n",
    "y_final = np.hstack((y_glauc, y_not_glauc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1240 samples, validate on 311 samples\n",
      "Epoch 1/1000\n",
      "  32/1240 [..............................] - ETA: 22:14 - loss: 3.8858 - acc: 0.5312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-836818aafa1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.fit_generator(generator=cup_train_data_gen, steps_per_epoch=104, epochs=40, verbose=1, callbacks=[model_checkpoint], validation_data=cup_val_data_gen, validation_steps=26, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/karimabedrabbo/keras/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1731\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/karimabedrabbo/keras/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karimabedrabbo/keras/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2634\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_checkpoint = ModelCheckpoint('karim_best_weights_new.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "#model.fit_generator(generator=cup_train_data_gen, steps_per_epoch=104, epochs=40, verbose=1, callbacks=[model_checkpoint], validation_data=cup_val_data_gen, validation_steps=26, shuffle=True)\n",
    "\n",
    "classifier_model.fit(x=np.array(x_final), y=np.array(y_final), batch_size=16, epochs=1000, verbose=1, callbacks=[model_checkpoint], validation_split=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
