{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Activation, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from scipy.misc import toimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getImageArr( path , width , height , imgNorm=\"sub_mean\" , odering='channels_last' ):\n",
    "\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        \n",
    "        if imgNorm == \"sub_and_divide\":\n",
    "            img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "        elif imgNorm == \"sub_mean\":\n",
    "            img = cv2.resize(img, ( width , height ))\n",
    "            img = img.astype(np.float32)\n",
    "            img[:,:,0] -= 103.939\n",
    "            img[:,:,1] -= 116.779\n",
    "            img[:,:,2] -= 123.68\n",
    "        elif imgNorm == \"divide\":\n",
    "            img = cv2.resize(img, ( width , height ))\n",
    "            img = img.astype(np.float32)\n",
    "            img = img/255.0\n",
    "\n",
    "        if odering == 'channels_first':\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "    except Exception, e:\n",
    "        print path , e\n",
    "        img = np.zeros((  height , width  , 3 ))\n",
    "        if odering == 'channels_first':\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        img = cv2.resize(img, ( width , height ))\n",
    "        img = img[:, : , 0]\n",
    "\n",
    "        for c in range(nClasses):\n",
    "            seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "\n",
    "    except Exception, e:\n",
    "        print e\n",
    "\n",
    "    seg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
    "    return seg_labels\n",
    "\n",
    "def imageSegmentationGenerator( images_path , segs_path ,  batch_size,  n_classes , input_height , input_width , output_height , output_width   ):\n",
    "    \n",
    "    assert images_path[-1] == '/'\n",
    "    assert segs_path[-1] == '/'\n",
    "\n",
    "    images = glob.glob( images_path + \"*.jpg\"  ) + glob.glob( images_path + \"*.png\"  ) +  glob.glob( images_path + \"*.jpeg\"  )\n",
    "    images.sort()\n",
    "    segmentations  = glob.glob( segs_path + \"*.jpg\"  ) + glob.glob( segs_path + \"*.png\"  ) +  glob.glob( segs_path + \"*.jpeg\"  )\n",
    "    segmentations.sort()\n",
    "\n",
    "    assert len( images ) == len(segmentations)\n",
    "    for im , seg in zip(images,segmentations):\n",
    "        assert(  im.split('/')[-1].split(\".\")[0] ==  seg.split('/')[-1].split(\".\")[0] )\n",
    "\n",
    "    zipped = itertools.cycle( zip(images,segmentations) )\n",
    "\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range( batch_size) :\n",
    "            im , seg = zipped.next()\n",
    "            X.append( getImageArr(im , input_width , input_height )  )\n",
    "            Y.append( getSegmentationArr( seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "        yield np.array(X) , np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cross_entropy(y_, y_conv):\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "    return cross_entropy\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    y_true_f = K.clip(K.batch_flatten(y_true), 0., 1.)\n",
    "    y_pred_f = K.clip(K.batch_flatten(y_pred), 0., 1.)\n",
    "\n",
    "    intersection = 2 * K.sum(y_true_f * y_pred_f, axis=1)\n",
    "    union = K.sum(y_true_f * y_true_f, axis=1) + K.sum(y_pred_f * y_pred_f, axis=1)\n",
    "    return K.mean(intersection / union)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice(y_true, y_pred)\n",
    "\n",
    "\n",
    "def log_dice_loss(y_true, y_pred):\n",
    "    return -K.log(dice(y_true, y_pred))\n",
    "\n",
    "\n",
    "def dice_metric(y_true, y_pred):\n",
    "    \"\"\"An exact Dice score for binary tensors.\"\"\"\n",
    "    y_true_f = K.greater(y_true, 0.5)\n",
    "    y_pred_f = K.greater(y_pred, 0.5)\n",
    "    return dice(y_true_f, y_pred_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, 3), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        arr = imgs[i]\n",
    "        arr = arr.astype('float32')\n",
    "        arr /= 255.\n",
    "        imgs_p[i] = resize(arr, (img_cols, img_rows), preserve_range=True)\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_cup_train = np.load('gt_cup_train_new.npy')\n",
    "#imgs_orig_train = np.load('orig_cup_train_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_3():\n",
    "    model_vgg19_conv = VGG19(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "    conv2_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv2_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-17].output)\n",
    "\n",
    "    conv3_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv3_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-12].output)\n",
    "\n",
    "    conv4_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv4_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-7].output)\n",
    "\n",
    "    conv5_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv5_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-2].output)\n",
    "\n",
    "    upsample2_ = Conv2DTranspose(filters=16, kernel_size=(4, 4), strides=(2, 2), padding = \"same\", name= \"upsample2_\", data_format=\"channels_last\")(conv2_3_16)\n",
    "    \n",
    "    upsample4_ = Conv2DTranspose(filters=16, kernel_size=(8, 8), strides=(4, 4), padding = \"same\", name= \"upsample4_\", data_format=\"channels_last\")(conv3_3_16)\n",
    "\n",
    "    upsample8_ = Conv2DTranspose(filters=16, kernel_size=(16, 16), strides=(8, 8), padding = \"same\",  name= \"upsample8_\", data_format=\"channels_last\")(conv4_3_16)\n",
    "\n",
    "    upsample16_ = Conv2DTranspose(filters=16, kernel_size=(32, 32), strides=(16, 16), padding = \"same\", name= \"upsample16_\", data_format=\"channels_last\")(conv5_3_16)\n",
    "\n",
    "    concat_upscore = concatenate([upsample2_, upsample4_, upsample8_, upsample16_], axis=-1)\n",
    "    \n",
    "    \"\"\"\n",
    "    new_score_weighting = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid', kernel_initializer=keras.initializers.Constant(value=0.01), name= \"new_score_weighting\", data_format=\"channels_last\")(concat_upscore)\n",
    "    \n",
    "    my_model = Model(input=model_vgg19_conv.input , output=new_score_weighting)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    conv6 = Conv2D(filters=1, kernel_size=(1,1), activation='relu', kernel_initializer=keras.initializers.Constant(value=0.01), name= \"conv6\", data_format=\"channels_last\", border_mode='same')(concat_upscore)\n",
    "    conv6 = Reshape((1,256*256))(conv6)\n",
    "    conv6 = Permute((2,1))(conv6)\n",
    "\n",
    "    conv7 = Activation('softmax')(conv6)\n",
    "\n",
    "    my_model = Model(input=model_vgg19_conv.input, output=conv7)\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Dense, Dropout, Activation, Flatten, Reshape, concatenate, Permute\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D , ZeroPadding3D , UpSampling3D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam , SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model_2(nClasses , optimizer=None , input_width=256 , input_height=256 , nChannels=3): \n",
    "    \n",
    "    inputs = Input((input_height, input_width, nChannels))\n",
    "    conv1 = Convolution2D(32, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Convolution2D(32, kernel_size=(3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Convolution2D(64, kernel_size=(3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Convolution2D(64, kernel_size=(3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Convolution2D(128, kernel_size=(3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Convolution2D(128, kernel_size=(3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = Convolution2D(64, kernel_size=(3, 3), activation='relu', padding='same')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Convolution2D(64, kernel_size=(3, 3), activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = Convolution2D(32, kernel_size=(3, 3), activation='relu', padding='same')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Convolution2D(32, kernel_size=(3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    conv6 = Convolution2D(nClasses, kernel_size=(1, 1), activation='relu',padding='same')(conv5)\n",
    "    conv6 = core.Reshape((nClasses,input_height*input_width))(conv6)\n",
    "    conv6 = core.Permute((2,1))(conv6)\n",
    "\n",
    "\n",
    "    conv7 = core.Activation('softmax')(conv6)\n",
    "\n",
    "    model = Model(input=inputs, output=conv7)\n",
    "\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model_vgg19_conv = VGG19(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "    conv2_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv2_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-17].output)\n",
    "\n",
    "    conv3_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv3_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-12].output)\n",
    "\n",
    "    conv4_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv4_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-7].output)\n",
    "\n",
    "    conv5_3_16 = Conv2D(filters=16, kernel_size=(3, 3), padding = \"same\", kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.001), name= \"conv5_3_16\", data_format=\"channels_last\")(model_vgg19_conv.layers[-2].output)\n",
    "\n",
    "    upsample2_ = Conv2DTranspose(filters=16, kernel_size=(4, 4), strides=(2, 2), padding = \"same\", name= \"upsample2_\", data_format=\"channels_last\")(conv2_3_16)\n",
    "    \n",
    "    upsample4_ = Conv2DTranspose(filters=16, kernel_size=(8, 8), strides=(4, 4), padding = \"same\", name= \"upsample4_\", data_format=\"channels_last\")(conv3_3_16)\n",
    "\n",
    "    upsample8_ = Conv2DTranspose(filters=16, kernel_size=(16, 16), strides=(8, 8), padding = \"same\",  name= \"upsample8_\", data_format=\"channels_last\")(conv4_3_16)\n",
    "\n",
    "    upsample16_ = Conv2DTranspose(filters=16, kernel_size=(32, 32), strides=(16, 16), padding = \"same\", name= \"upsample16_\", data_format=\"channels_last\")(conv5_3_16)\n",
    "\n",
    "    concat_upscore = concatenate([upsample2_, upsample4_, upsample8_, upsample16_], axis=-1)\n",
    "    \n",
    "    new_score_weighting = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid', kernel_initializer=keras.initializers.Constant(value=0.01), name= \"new_score_weighting\", data_format=\"channels_last\")(concat_upscore)\n",
    "    \n",
    "    my_model = Model(input=model_vgg19_conv.input , output=new_score_weighting)\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ne..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_16 (Conv2D)             (None, 128, 128, 16) 18448       block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_16 (Conv2D)             (None, 64, 64, 16)   36880       block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_16 (Conv2D)             (None, 32, 32, 16)   73744       block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_16 (Conv2D)             (None, 16, 16, 16)   73744       block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsample2_ (Conv2DTranspose)    (None, 256, 256, 16) 4112        conv2_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "upsample4_ (Conv2DTranspose)    (None, 256, 256, 16) 16400       conv3_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "upsample8_ (Conv2DTranspose)    (None, 256, 256, 16) 65552       conv4_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "upsample16_ (Conv2DTranspose)   (None, 256, 256, 16) 262160      conv5_3_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 64) 0           upsample2_[0][0]                 \n",
      "                                                                 upsample4_[0][0]                 \n",
      "                                                                 upsample8_[0][0]                 \n",
      "                                                                 upsample16_[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 256, 256, 1)  65          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 65536)     0           conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 65536, 1)     0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 65536, 1)     0           permute_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,575,489\n",
      "Trainable params: 20,575,489\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"log_dice_weights_200_iter.h5\")\n",
    "adam = Adam(lr=.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss=tf.losses.sigmoid_cross_entropy)\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_orig_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-35f02cc73d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgs_orig_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgs_cup_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs_orig_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x=imgs_orig_train, y=imgs_cup_train, batch_size=16, epochs=40, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.jpg src is not a numpy array, neither a scalar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = [  ( random.randint(0,255),random.randint(0,255),random.randint(0,255)   ) for _ in range(1)  ]\n",
    "X = getImageArr(\"31.jpg\" , 256  , 256, \"divide\"  )\n",
    "X = np.expand_dims(X, 0)\n",
    "pr = model.predict( np.array(X) )\n",
    "pr = pr.reshape(( 256 ,  256 , 1 ) ).argmax( axis=2 )\n",
    "seg_img = np.zeros( ( 256 , 256 , 3  ) )\n",
    "for c in range(1):\n",
    "    seg_img[:,:,0] += ( (pr[:,: ] == c )*( colors[c][0] )).astype('uint8')\n",
    "    seg_img[:,:,1] += ((pr[:,: ] == c )*( colors[c][1] )).astype('uint8')\n",
    "    seg_img[:,:,2] += ((pr[:,: ] == c )*( colors[c][2] )).astype('uint8')\n",
    "seg_img = cv2.resize(seg_img  , (256 , 256 ))\n",
    "cv2.imwrite(  \"final.jpg\" , seg_img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(  \"final2.jpg\" , pr.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "new_img = Image.open(\"31.jpg\")\n",
    "if new_img.mode != 'RGB':\n",
    "    new_img = new_img.convert('RGB')\n",
    "# new_img.show()\n",
    "new_arr = np.array(new_img)\n",
    "new_arr = new_arr/255.\n",
    "new_arr = np.expand_dims(new_arr, axis = 0)\n",
    "print(new_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(new_arr)\n",
    "prediction = prediction*255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "prediction = np.squeeze(prediction)\n",
    "if prediction.shape == (65536,):\n",
    "    prediction = np.reshape(prediction, (256,256))\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = Image.fromarray(prediction)\n",
    "if pred_img.mode != 'RGB':\n",
    "    pred_img = pred_img.convert('RGB')\n",
    "pred_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "def getImageArr( path , width , height , imgNorm=\"sub_mean\" , odering='channels_first' ):\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(path, 1)\n",
    "\n",
    "        if imgNorm == \"sub_and_divide\":\n",
    "            img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "        elif imgNorm == \"sub_mean\":\n",
    "            img = cv2.resize(img, ( width , height ))\n",
    "            img = img.astype(np.float32)\n",
    "            img[:,:,0] -= 103.939\n",
    "            img[:,:,1] -= 116.779\n",
    "            img[:,:,2] -= 123.68\n",
    "        elif imgNorm == \"divide\":\n",
    "            img = cv2.resize(img, ( width , height ))\n",
    "            img = img.astype(np.float32)\n",
    "            img = img/255.0\n",
    "\n",
    "        if odering == 'channels_first':\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "    except Exception, e:\n",
    "        print path , e\n",
    "        img = np.zeros((  height , width  , 3 ))\n",
    "        if odering == 'channels_first':\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    try:\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = cv2.resize(img, ( width , height ))\n",
    "        img = img[:, : , 0]\n",
    "\n",
    "        for c in range(nClasses):\n",
    "            seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "\n",
    "    except Exception, e:\n",
    "        print e\n",
    "\n",
    "    seg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
    "    return seg_labels\n",
    "\n",
    "def imageSegmentationGenerator( images_path , segs_path ,  batch_size,  n_classes , input_height , input_width , output_height , output_width   ):\n",
    "    \n",
    "    assert images_path[-1] == '/'\n",
    "    assert segs_path[-1] == '/'\n",
    "\n",
    "    images = glob.glob( images_path + \"*.jpg\"  ) + glob.glob( images_path + \"*.png\"  ) +  glob.glob( images_path + \"*.jpeg\"  )\n",
    "    images.sort()\n",
    "    segmentations  = glob.glob( segs_path + \"*.jpg\"  ) + glob.glob( segs_path + \"*.png\"  ) +  glob.glob( segs_path + \"*.jpeg\"  )\n",
    "    segmentations.sort()\n",
    "\n",
    "    assert len( images ) == len(segmentations)\n",
    "    for im , seg in zip(images,segmentations):\n",
    "        assert(  im.split('/')[-1].split(\".\")[0] ==  seg.split('/')[-1].split(\".\")[0] )\n",
    "\n",
    "    zipped = itertools.cycle( zip(images,segmentations) )\n",
    "\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range( batch_size) :\n",
    "            im , seg = zipped.next()\n",
    "            X.append( getImageArr(im , input_width , input_height )  )\n",
    "            Y.append( getSegmentationArr( seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "        yield np.array(X) , np.array(Y)\n",
    "\n",
    "\n",
    "# import Models , LoadBatches\n",
    "# G  = LoadBatches.imageSegmentationGenerator( \"data/clothes_seg/prepped/images_prepped_train/\" ,  \"data/clothes_seg/prepped/annotations_prepped_train/\" ,  1,  10 , 800 , 550 , 400 , 272   ) \n",
    "# G2  = LoadBatches.imageSegmentationGenerator( \"data/clothes_seg/prepped/images_prepped_test/\" ,  \"data/clothes_seg/prepped/annotations_prepped_test/\" ,  1,  10 , 800 , 550 , 400 , 272   ) \n",
    "\n",
    "# m = Models.VGGSegnet.VGGSegnet( 10  , use_vgg_weights=True ,  optimizer='adadelta' , input_image_size=( 800 , 550 )  )\n",
    "# m.fit_generator( G , 512  , nb_epoch=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_gt_path = \"/Users/karimabedrabbo/Desktop/Version 18 - Training Cup Segementation CNN/cropped_augmentations_unblurred_resized/train/cup\"\n",
    "training_orig_path = \"/Users/karimabedrabbo/Desktop/Version 18 - Training Cup Segementation CNN/cropped_augmentations_unblurred_resized/train/norm\"\n",
    "cup_train_data_gen = imageSegmentationGenerator(training_orig_path, training_gt_path, 16, 2, 256, 256, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_masks = np.load(\"imgs_mask_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_masks = unet_masks * 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(np.squeeze(unet_masks[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
